{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0f8f14-67ac-4171-9c2c-8feb64d99461",
   "metadata": {},
   "source": [
    "# 00. PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f564e7-41f5-42d3-a384-8ec6ef8e2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd444df5-cf4f-4485-845b-7ec109f4f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Name: Quadro K2200\n"
     ]
    }
   ],
   "source": [
    "cuda_available  = torch.cuda.is_available()\n",
    "if cuda_available:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"CUDA Device Name: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d7d53-4a52-4170-9cf8-5e7ab2d2fd91",
   "metadata": {},
   "source": [
    "# Introduction to Tensor\n",
    "## Creating Tensors\n",
    "torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e1f772-9f4d-4108-beeb-54bb7b70ccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar \n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d46503-89ea-44c3-b72f-784619efd60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632aed9c-2724-4f76-a3ee-3b63ac662887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7a64c8-0023-4b4c-9988-0e05dbcc38b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9b87d5-484f-4184-85b8-520278bd023b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b4277a-2c50-4abb-a80f-ded15ff4da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871556cb-db57-4d73-ae5e-90189f5fecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 9],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7, 9], [4, 3]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f29c363-14c2-43d9-80aa-b9c2910240f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39bc3779-0636-4f6a-a955-204a8e41878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c43fbcf-7f67-4502-aa29-ded426383a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4,  3,  2],\n",
       "         [ 6, 32,  2]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[4, 3, 2], [6, 32, 2]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2628f2de-2485-4d1c-a7e2-b320e01d61f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10d6b7eb-8e9d-4f60-83cd-f05551099ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27748c0-ec2f-47f3-b964-81102dd7a041",
   "metadata": {},
   "source": [
    "# Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f41932e-e235-4eea-89a0-99facd38c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0132, 0.4295, 0.0439, 0.0313],\n",
       "         [0.2823, 0.4761, 0.3417, 0.9601],\n",
       "         [0.9098, 0.2871, 0.7525, 0.6815]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a461366-fcce-4d38-b47f-09220e0f94f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "639a0ff4-d5bf-4a0f-b390-eb0cdd8b6f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c37f613a-65c3-42b2-b4af-d34c4b2a1736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape of an image tensor\n",
    "random_image_size_tensor =  torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c4ff7-d0d5-4698-8194-bf96bbfd47d4",
   "metadata": {},
   "source": [
    "# Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a696d608-ff2b-4751-b293-43fe05bfad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 3))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "110c264b-86ca-4a00-97a6-fad5f490c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 3))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ad3d70-df3b-42e1-8d6a-22304f1d2d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d530b-d69e-4276-8d93-985e5a48bd00",
   "metadata": {},
   "source": [
    "# Creating a range of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71180235-e3ca-4872-a510-d660b893c472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_to_ten = torch.arange(1, 11)\n",
    "one_to_ten = torch.arange(start=1, end=10, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01da2cf6-0f7d-48c0-a303-77ce03cf01f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tensors like\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18f444-5a57-4280-9d42-957a668b5788",
   "metadata": {},
   "source": [
    "# Tensor DataTypes\n",
    "*Note:* Tensor datatypes is one of the 3 big errors in PyTorch & Deep Learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92a56983-fa2f-4a11-9764-4175e1d82130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5., 3.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float32 Tensor\n",
    "float_32_tensor = torch.tensor([2.0, 5.0, 3.0],\n",
    "                               dtype=None, # What datatype is your tensor(eg. float32 or float16)\n",
    "                               device=None,# What device is your tensor on\n",
    "                               requires_grad=False # Whether or not track the gradients with this tensor operations\n",
    "                              )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "234d0958-fcc5-41d5-b365-a655fbd4e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c616a812-4d51-45fd-8571-21ab9be92bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd4ec50d-175f-4dfd-b24a-5297920f7b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = float_32_tensor.type(torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f5711e9-3b90-4acf-8ae9-3b6cb6d239d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., 25.,  9.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb75fa6-d573-45f8-9bba-72843982ca2c",
   "metadata": {},
   "source": [
    "# Get Information from Tensors\n",
    "1. Tensors not right datatype - to do get datatype from a tensor, can use `tensor.dtype` \n",
    "2. Tensors not right shape - to get shape from tensor, can use `tensor.shape`\n",
    "3. Tensors not on the right device - to get a device from a tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a00ca059-437b-4e95-8392-1dc7e1b04bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7086, 0.5851, 0.7621, 0.6143],\n",
       "        [0.8349, 0.0536, 0.6494, 0.6956],\n",
       "        [0.1861, 0.6014, 0.9281, 0.7583]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f400c920-47fa-42ed-ab8f-4df5a9e73167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7086, 0.5851, 0.7621, 0.6143],\n",
      "        [0.8349, 0.0536, 0.6494, 0.6956],\n",
      "        [0.1861, 0.6014, 0.9281, 0.7583]]) \n",
      "\n",
      "DataType of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor, \"\\n\")\n",
    "print(f\"DataType of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef07961-63d1-4755-8e55-e7a801e2cef7",
   "metadata": {},
   "source": [
    "## Manipulating Tensors\n",
    "### Tensor Operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e90ffcc9-7208-4296-9350-da935617de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ded9823-6570-4d1e-9827-44652ada4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 13, 15])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc3779a0-a76d-4013-9a2a-2e01ec3c50ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -7, -5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction \n",
    "tensor - 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1498f99-07ff-414a-a348-47598f2b46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 30, 50])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6ba9898-1afd-43ab-a00d-a207940ad2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.6000, 1.0000])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "tensor / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f04877f8-b393-404a-9fc0-247f4c8da716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35)\n"
     ]
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d74a394a-ba04-44e4-8a81-8143ea353c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.matmul(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba2c9e-ccc9-434d-8afb-9c008bfe22c9",
   "metadata": {},
   "source": [
    "# Matrix multiplication (is all you need)\n",
    "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
    "\n",
    "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "The inner dimensions must match:\n",
    " `(3, 2) @ (3, 2)` won't work\n",
    " `(2, 3) @ (3, 2)` will work\n",
    " `(3, 2) @ (2, 3)` will work\n",
    "The resulting matrix has the shape of the outer dimensions:\n",
    " `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    " **Note:** \"@\" in Python is the symbol for matrix multiplication.\n",
    "\n",
    " **Resource:** You can see all of the rules for matrix multiplication using torch.matmul() in the PyTorch documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8014a112-afbf-40bb-b6f7-05e3cf9e66a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5286, 0.5315],\n",
       "        [0.5619, 0.6205]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(2, 3), torch.rand(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71347ab7-fbc6-4810-838e-c68a67ee0e6e",
   "metadata": {},
   "source": [
    "## One of the most common errors in DL: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a65912-5296-4c67-8321-56428a758c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor(\n",
    "        [[1, 2],\n",
    "         [3, 4], \n",
    "         [5, 6], \n",
    "         [7, 8]]\n",
    ")\n",
    "tensor_B = torch.tensor(\n",
    "        [[1, 2],\n",
    "         [3, 4], \n",
    "         [5, 6], \n",
    "         [7, 8]]\n",
    ")\n",
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fe00d-7fc1-4a5b-92ae-a93fe0cde340",
   "metadata": {},
   "source": [
    "### To fix our tensor shape issues, we can manipulate the shape of one of our tensor using **transpose**.\n",
    "\n",
    "A **Transpose** switches the axis or dimentions for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c3ec796-e5aa-427b-ba92-2038ef6d8148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6],\n",
       "         [7, 8]]),\n",
       " torch.Size([4, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad9b0fa-5260-443f-ba61-7677e7cfa8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 3, 5, 7],\n",
       "         [2, 4, 6, 8]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6b0ff1-2d3d-408b-a221-e6ada64bee03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,  11,  17,  23],\n",
       "        [ 11,  25,  39,  53],\n",
       "        [ 17,  39,  61,  83],\n",
       "        [ 23,  53,  83, 113]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, Multiply\n",
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f030ab-c316-4448-87a9-83d33970c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([4, 2]), tensor_B = torch.Size([4, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([4, 2]) (same as above), tensor_B.T = torch.Size([2, 4])\n",
      "\n",
      "Multiplying: torch.Size([4, 2]) * torch.Size([2, 4]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[  5,  11,  17,  23],\n",
      "        [ 11,  25,  39,  53],\n",
      "        [ 17,  39,  61,  83],\n",
      "        [ 23,  53,  83, 113]])\n",
      "\n",
      "Output shape: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043d082-8ccb-4a74-a425-ec7d457731aa",
   "metadata": {},
   "source": [
    "## Find the min, max, mean, sum and etc (Tensor Aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dab8ea7-9001-4e05-93ac-be250b45030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64287549-d075-4632-b654-cafe8c1c367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b02b91b-2c6b-49db-9910-34ae3f14ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36b91eb7-b74b-4414-9c4b-bc026d846379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean \n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee25ba4-0f00-4e57-9be4-3aad465d9619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b370cd-3482-4d0f-96c4-c212989a5e14",
   "metadata": {},
   "source": [
    "## Find the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f85a5e46-f41b-4fb8-9d9a-99613938a33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99984eed-c417-4e28-b57b-900cfdd25367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(x), x.argmin() # return the minimum value index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939954e9-244a-439a-80d7-2ec443da1635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x), x.argmax() # return the maximum value index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921e6d4-ace7-458b-861a-aaf191e42d04",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9358b1ee-c2d5-4832-b37d-ffe187b978ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aff2a1e-de64-4aaf-8181-a9662b5196eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20128a3a-8ebe-4fbd-a3cc-4e07d1379123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "# See more: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape\n",
    "#Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor.\n",
    "#So changing the view changes the original tensor too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccc8b83e-3fd0-4919-a0a7-74aa3bd2843d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "712e7f6a-cb6e-475d-ac2d-b3a975cbb4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we wanted to stack our new tensor on top of itself five times, we could do so with torch.stack().\n",
    "torch.stack([x, x, x], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2fc4e5-e454-42d0-8ac5-e7b84a8eed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.],\n",
       "        [6., 6., 6.],\n",
       "        [7., 7., 7.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacted = torch.stack([x, x, x], dim=1)\n",
    "x_stacted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e18767-8a4a-46b4-8388-83d388e43be1",
   "metadata": {},
   "source": [
    "#### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3fcfda9-62c8-4f27-8fe1-adfa3e48ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5., 5., 5.],\n",
       "          [2., 2., 2.],\n",
       "          [3., 3., 3.],\n",
       "          [4., 4., 4.],\n",
       "          [5., 5., 5.],\n",
       "          [6., 6., 6.],\n",
       "          [7., 7., 7.]]]),\n",
       " torch.Size([1, 7, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_x = x_stacted.reshape(1, x_stacted.shape[0], x_stacted.shape[1])\n",
    "reshaped_x, reshaped_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbe4c2dc-bce5-4086-9762-533c546bd9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.],\n",
       "        [6., 6., 6.],\n",
       "        [7., 7., 7.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = torch.squeeze(reshaped_x)\n",
    "x_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00f7ccf6-dbab-4b52-ba02-d909c6be92a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 5., 5.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [4., 4., 4.],\n",
      "        [5., 5., 5.],\n",
      "        [6., 6., 6.],\n",
      "        [7., 7., 7.]])\n",
      "Previous shape: torch.Size([7, 3])\n",
      "\n",
      "New tensor: tensor([[[5., 5., 5.],\n",
      "         [2., 2., 2.],\n",
      "         [3., 3., 3.],\n",
      "         [4., 4., 4.],\n",
      "         [5., 5., 5.],\n",
      "         [6., 6., 6.],\n",
      "         [7., 7., 7.]]])\n",
      "New shape: torch.Size([1, 7, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56224a99-8fd3-479f-a6d3-500ad3ae3aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d2f102e-fe97-42eb-a2a8-493256722c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_permuted[0, 0, 0] = 32238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a49b6617-c2a5-4649-8f91-853f076eb353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.2238e+04, 4.2852e-01, 6.3957e-01],\n",
       "         [3.2998e-01, 9.4714e-02, 9.0208e-01],\n",
       "         [7.1187e-01, 2.8438e-01, 2.8899e-01],\n",
       "         ...,\n",
       "         [3.4741e-01, 2.0506e-01, 9.5081e-01],\n",
       "         [8.9125e-01, 2.6352e-01, 4.2032e-01],\n",
       "         [6.0079e-01, 5.4459e-01, 8.2016e-01]],\n",
       "\n",
       "        [[8.6969e-01, 4.9074e-01, 4.4521e-01],\n",
       "         [6.9862e-02, 7.0972e-01, 2.3369e-01],\n",
       "         [4.2526e-01, 7.9322e-01, 8.6158e-01],\n",
       "         ...,\n",
       "         [7.2117e-01, 5.9521e-01, 1.0375e-01],\n",
       "         [7.0762e-01, 8.1744e-01, 8.6922e-02],\n",
       "         [9.1785e-01, 1.6030e-01, 2.7802e-01]],\n",
       "\n",
       "        [[9.4222e-01, 6.7794e-01, 4.7585e-01],\n",
       "         [4.3240e-01, 3.2291e-01, 8.5225e-01],\n",
       "         [6.2540e-01, 7.1849e-01, 5.8896e-01],\n",
       "         ...,\n",
       "         [8.0063e-01, 9.3585e-01, 3.3609e-02],\n",
       "         [7.4892e-01, 6.0609e-01, 2.5200e-01],\n",
       "         [4.2307e-01, 6.6973e-01, 4.6882e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.3727e-01, 3.3170e-02, 5.6324e-01],\n",
       "         [1.5779e-01, 6.3599e-02, 3.8100e-02],\n",
       "         [9.8948e-01, 8.4056e-01, 3.5744e-01],\n",
       "         ...,\n",
       "         [6.5527e-01, 5.7677e-01, 1.0273e-01],\n",
       "         [1.0157e-01, 8.5245e-01, 1.2109e-01],\n",
       "         [8.2196e-01, 5.5949e-01, 7.4380e-01]],\n",
       "\n",
       "        [[2.2278e-01, 2.3016e-01, 1.0612e-01],\n",
       "         [1.8025e-01, 6.8371e-01, 7.9955e-01],\n",
       "         [3.5242e-01, 2.4107e-02, 1.0489e-01],\n",
       "         ...,\n",
       "         [5.6010e-01, 7.7710e-01, 9.0431e-01],\n",
       "         [1.6764e-01, 2.0500e-01, 1.4553e-01],\n",
       "         [3.7221e-01, 1.5922e-01, 1.9243e-01]],\n",
       "\n",
       "        [[4.2582e-01, 2.4938e-01, 8.5114e-01],\n",
       "         [4.8565e-01, 6.4595e-02, 2.9774e-01],\n",
       "         [3.8928e-01, 8.3038e-01, 6.4086e-01],\n",
       "         ...,\n",
       "         [9.3003e-01, 3.1956e-01, 4.6512e-01],\n",
       "         [6.8293e-01, 1.1450e-01, 9.3540e-01],\n",
       "         [7.6413e-01, 1.9119e-01, 3.8565e-02]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f277504-7d4d-4bc4-ac63-539b7767e777",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42968a64-9018-412b-a153-49c7f2f17074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d96892d-d44f-4928-9d62-26b2a5b40d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30d761a1-e5a2-499b-afc3-ec6a88db0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return [3, 6, 9]\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b89bac08-57b1-4446-bc79-f29a11771414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc6e0038-c65f-4ae7-b0be-3e2d3624f514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fade0aa0-a0da-471a-8919-1446603ce0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65299540-db2c-4e5f-ba6d-e2e9a79f7496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92398a25-4342-4fa3-8600-df55101ed4cd",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a7c1b8d-c6f1-4ad2-b816-3879b762641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abf74f-e70d-4639-960d-4e00b2721683",
   "metadata": {},
   "source": [
    "Note: By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
    "\n",
    "However, many PyTorch calculations default to using float32.\n",
    "\n",
    "So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2498114-18b6-4766-88a0-25c2bd15b8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the array, keep the tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1509b8c-ca0c-4f5e-b3af-df7ce94c146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2723849b-adaf-4c08-aca6-ea960e94f066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab54e0-abd1-48dc-9b00-abe584d76faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
